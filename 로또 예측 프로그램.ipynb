{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17710,
     "status": "ok",
     "timestamp": 1686819599013,
     "user": {
      "displayName": "김민우",
      "userId": "15651798176472178488"
     },
     "user_tz": -540
    },
    "id": "ftAIsmkmd2e8",
    "outputId": "0b005aaa-f7c8-49e4-e7f1-7497d531d1d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0378\n",
      "Epoch [200/1000], Loss: 0.0332\n",
      "Epoch [300/1000], Loss: 0.0306\n",
      "Epoch [400/1000], Loss: 0.0289\n",
      "Epoch [500/1000], Loss: 0.0279\n",
      "Epoch [600/1000], Loss: 0.0277\n",
      "Epoch [700/1000], Loss: 0.0273\n",
      "Epoch [800/1000], Loss: 0.0272\n",
      "Epoch [900/1000], Loss: 0.0272\n",
      "Epoch [1000/1000], Loss: 0.0270\n",
      "2023년 6월 로또 번호 예측: [ 6 12 19 26 32 39 22]\n"
     ]
    }
   ],
   "source": [
    "#로또번호 예측 트랜스포머\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('lotto.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.iloc[:, 1:].values)  # 날짜 열 제외, 수치 데이터 스케일링\n",
    "\n",
    "# 훈련 데이터 준비\n",
    "train_data = scaled_data[:-6]  # 마지막 6개 행 제외\n",
    "train_inputs = torch.tensor(train_data[:-1]).unsqueeze(0).float()  # 입력 데이터\n",
    "train_labels = torch.tensor(train_data[1:]).unsqueeze(0).float()  # 출력 데이터\n",
    "\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class LottoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, inputs, labels):\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.labels[index]\n",
    "\n",
    "# 트랜스포머 모델 정의\n",
    "class LottoTransformer(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads):\n",
    "        super(LottoTransformer, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(input_size, num_heads, hidden_size),\n",
    "            num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_size = train_inputs.shape[-1]\n",
    "hidden_size = 64\n",
    "output_size = train_labels.shape[-1]''\n",
    "num_layers = 4\n",
    "num_heads = 4\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "batch_size = 32\n",
    "\n",
    "# 데이터 로더 초기화\n",
    "dataset = LottoDataset(train_inputs, train_labels)\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 모델 초기화\n",
    "model = LottoTransformer(input_size, hidden_size, output_size, num_layers, num_heads)\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 훈련\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_inputs, batch_labels in data_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_inputs)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 테스트 데이터 준비\n",
    "test_inputs = torch.tensor(scaled_data[-3:-1]).unsqueeze(0).float()\n",
    "\n",
    "# 모델 예측\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted = model(test_inputs)\n",
    "\n",
    "# 스케일링 역변환\n",
    "predicted = scaler.inverse_transform(predicted.squeeze(0).numpy())\n",
    "\n",
    "# 예측 결과 출력\n",
    "lotto_numbers_prediction = predicted[-1].astype(int)[:-5]  # 마지막 5개 원소 제외\n",
    "print(f'2023년 6월 로또 번호 예측: {lotto_numbers_prediction}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29258,
     "status": "ok",
     "timestamp": 1686728878784,
     "user": {
      "displayName": "김민우",
      "userId": "15651798176472178488"
     },
     "user_tz": -540
    },
    "id": "0Gq1eDSmJ4wv",
    "outputId": "bc449a46-92b7-4c13-9d34-029c8aea76ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0216\n",
      "Epoch [200/1000], Loss: 0.0108\n",
      "Epoch [300/1000], Loss: 0.0072\n",
      "Epoch [400/1000], Loss: 0.0056\n",
      "Epoch [500/1000], Loss: 0.0047\n",
      "Epoch [600/1000], Loss: 0.0041\n",
      "Epoch [700/1000], Loss: 0.0036\n",
      "Epoch [800/1000], Loss: 0.0032\n",
      "Epoch [900/1000], Loss: 0.0029\n",
      "Epoch [1000/1000], Loss: 0.0026\n",
      "2023년 4월의 코스피지수 예측: 2266.60\n"
     ]
    }
   ],
   "source": [
    "#코스피 주가지수 예측 트랜스포머 (기본)\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('data100.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.iloc[:, 1:].values)  # 날짜 열 제외, 수치 데이터 스케일링\n",
    "\n",
    "# 훈련 데이터 준비\n",
    "train_data = scaled_data[:-1]  # 마지막 행 제외\n",
    "train_inputs = torch.tensor(train_data[:-1]).unsqueeze(0).float()  # 입력 데이터\n",
    "train_labels = torch.tensor(train_data[1:]).unsqueeze(0).float()  # 출력 데이터\n",
    "\n",
    "# 트랜스포머 모델 정의\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(input_size, num_heads, hidden_size),\n",
    "            num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_size = train_inputs.shape[-1]\n",
    "hidden_size = 64\n",
    "output_size = train_labels.shape[-1]\n",
    "num_layers = 6 #로또와 달리 데이터셋이 커 layer 4에서 6증가\n",
    "num_heads = 4\n",
    "num_epochs = 1000 #찾는 횟수\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 모델 초기화\n",
    "model = TransformerModel(input_size, hidden_size, output_size, num_layers, num_heads)\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 모델 훈련\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_inputs)\n",
    "    loss = criterion(outputs, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 테스트 데이터 준비\n",
    "test_inputs = torch.tensor(scaled_data[-2]).unsqueeze(0).float()\n",
    "\n",
    "# 모델 예측\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted = model(test_inputs)\n",
    "\n",
    "# 스케일링 역변환\n",
    "predicted = scaler.inverse_transform(predicted.squeeze().unsqueeze(0).numpy())\n",
    "\n",
    "# 예측 결과 출력\n",
    "kospis_index_prediction = predicted[0][-1]\n",
    "\n",
    "print(f'2023년 4월의 코스피지수 예측: {kospis_index_prediction:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 268984,
     "status": "ok",
     "timestamp": 1686761341359,
     "user": {
      "displayName": "김민우",
      "userId": "15651798176472178488"
     },
     "user_tz": -540
    },
    "id": "uNwVx2M4Mc0z",
    "outputId": "dc7553bb-4163-40c6-d19b-48f3cf786ba0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0200\n",
      "Epoch [200/1000], Loss: 0.0106\n",
      "Epoch [300/1000], Loss: 0.0073\n",
      "Epoch [400/1000], Loss: 0.0057\n",
      "Epoch [500/1000], Loss: 0.0047\n",
      "Epoch [600/1000], Loss: 0.0040\n",
      "Epoch [700/1000], Loss: 0.0036\n",
      "Epoch [800/1000], Loss: 0.0031\n",
      "Epoch [900/1000], Loss: 0.0028\n",
      "Epoch [1000/1000], Loss: 0.0027\n",
      "Epoch [100/1000], Loss: 0.0215\n",
      "Epoch [200/1000], Loss: 0.0102\n",
      "Epoch [300/1000], Loss: 0.0073\n",
      "Epoch [400/1000], Loss: 0.0059\n",
      "Epoch [500/1000], Loss: 0.0049\n",
      "Epoch [600/1000], Loss: 0.0041\n",
      "Epoch [700/1000], Loss: 0.0036\n",
      "Epoch [800/1000], Loss: 0.0032\n",
      "Epoch [900/1000], Loss: 0.0029\n",
      "Epoch [1000/1000], Loss: 0.0027\n",
      "Epoch [100/1000], Loss: 0.0182\n",
      "Epoch [200/1000], Loss: 0.0103\n",
      "Epoch [300/1000], Loss: 0.0072\n",
      "Epoch [400/1000], Loss: 0.0056\n",
      "Epoch [500/1000], Loss: 0.0046\n",
      "Epoch [600/1000], Loss: 0.0039\n",
      "Epoch [700/1000], Loss: 0.0035\n",
      "Epoch [800/1000], Loss: 0.0032\n",
      "Epoch [900/1000], Loss: 0.0028\n",
      "Epoch [1000/1000], Loss: 0.0026\n",
      "Epoch [100/1000], Loss: 0.0239\n",
      "Epoch [200/1000], Loss: 0.0113\n",
      "Epoch [300/1000], Loss: 0.0080\n",
      "Epoch [400/1000], Loss: 0.0063\n",
      "Epoch [500/1000], Loss: 0.0054\n",
      "Epoch [600/1000], Loss: 0.0045\n",
      "Epoch [700/1000], Loss: 0.0039\n",
      "Epoch [800/1000], Loss: 0.0035\n",
      "Epoch [900/1000], Loss: 0.0033\n",
      "Epoch [1000/1000], Loss: 0.0030\n",
      "Epoch [100/1000], Loss: 0.0214\n",
      "Epoch [200/1000], Loss: 0.0104\n",
      "Epoch [300/1000], Loss: 0.0073\n",
      "Epoch [400/1000], Loss: 0.0057\n",
      "Epoch [500/1000], Loss: 0.0048\n",
      "Epoch [600/1000], Loss: 0.0042\n",
      "Epoch [700/1000], Loss: 0.0037\n",
      "Epoch [800/1000], Loss: 0.0033\n",
      "Epoch [900/1000], Loss: 0.0030\n",
      "Epoch [1000/1000], Loss: 0.0027\n",
      "Epoch [100/1000], Loss: 0.0238\n",
      "Epoch [200/1000], Loss: 0.0108\n",
      "Epoch [300/1000], Loss: 0.0075\n",
      "Epoch [400/1000], Loss: 0.0058\n",
      "Epoch [500/1000], Loss: 0.0048\n",
      "Epoch [600/1000], Loss: 0.0039\n",
      "Epoch [700/1000], Loss: 0.0036\n",
      "Epoch [800/1000], Loss: 0.0032\n",
      "Epoch [900/1000], Loss: 0.0029\n",
      "Epoch [1000/1000], Loss: 0.0027\n",
      "Epoch [100/1000], Loss: 0.0225\n",
      "Epoch [200/1000], Loss: 0.0102\n",
      "Epoch [300/1000], Loss: 0.0073\n",
      "Epoch [400/1000], Loss: 0.0055\n",
      "Epoch [500/1000], Loss: 0.0047\n",
      "Epoch [600/1000], Loss: 0.0039\n",
      "Epoch [700/1000], Loss: 0.0035\n",
      "Epoch [800/1000], Loss: 0.0032\n",
      "Epoch [900/1000], Loss: 0.0029\n",
      "Epoch [1000/1000], Loss: 0.0026\n",
      "Epoch [100/1000], Loss: 0.0209\n",
      "Epoch [200/1000], Loss: 0.0102\n",
      "Epoch [300/1000], Loss: 0.0074\n",
      "Epoch [400/1000], Loss: 0.0056\n",
      "Epoch [500/1000], Loss: 0.0047\n",
      "Epoch [600/1000], Loss: 0.0040\n",
      "Epoch [700/1000], Loss: 0.0035\n",
      "Epoch [800/1000], Loss: 0.0032\n",
      "Epoch [900/1000], Loss: 0.0029\n",
      "Epoch [1000/1000], Loss: 0.0027\n",
      "Epoch [100/1000], Loss: 0.0193\n",
      "Epoch [200/1000], Loss: 0.0102\n",
      "Epoch [300/1000], Loss: 0.0070\n",
      "Epoch [400/1000], Loss: 0.0055\n",
      "Epoch [500/1000], Loss: 0.0045\n",
      "Epoch [600/1000], Loss: 0.0039\n",
      "Epoch [700/1000], Loss: 0.0034\n",
      "Epoch [800/1000], Loss: 0.0030\n",
      "Epoch [900/1000], Loss: 0.0027\n",
      "Epoch [1000/1000], Loss: 0.0026\n",
      "Epoch [100/1000], Loss: 0.0184\n",
      "Epoch [200/1000], Loss: 0.0093\n",
      "Epoch [300/1000], Loss: 0.0063\n",
      "Epoch [400/1000], Loss: 0.0049\n",
      "Epoch [500/1000], Loss: 0.0042\n",
      "Epoch [600/1000], Loss: 0.0036\n",
      "Epoch [700/1000], Loss: 0.0032\n",
      "Epoch [800/1000], Loss: 0.0029\n",
      "Epoch [900/1000], Loss: 0.0027\n",
      "Epoch [1000/1000], Loss: 0.0025\n",
      "Mean of Predicted KOSPI Index: 2315.17\n",
      "Standard Deviation of Predicted KOSPI Index: 54.58\n"
     ]
    }
   ],
   "source": [
    "#코스피 주가지수 예측 트랜스포머 (10회 실행 후 평균 및 표준편차)\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('data100.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.iloc[:, 1:].values)  # 날짜 열 제외, 수치 데이터 스케일링\n",
    "\n",
    "# 훈련 데이터 준비\n",
    "train_data = scaled_data[:-1]  # 마지막 행 제외\n",
    "train_inputs = torch.tensor(train_data[:-1]).unsqueeze(0).float()  # 입력 데이터\n",
    "train_labels = torch.tensor(train_data[1:]).unsqueeze(0).float()  # 출력 데이터\n",
    "\n",
    "# 트랜스포머 모델 정의\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(input_size, num_heads, hidden_size),\n",
    "            num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_size = train_inputs.shape[-1]\n",
    "hidden_size = 64\n",
    "output_size = train_labels.shape[-1]\n",
    "num_layers = 6\n",
    "num_heads = 4\n",
    "num_runs = 10  # 실행 횟수\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "predictions = []  # 예측 결과를 저장할 리스트\n",
    "\n",
    "for _ in range(num_runs):\n",
    "    # 모델 초기화\n",
    "    model = TransformerModel(input_size, hidden_size, output_size, num_layers, num_heads)\n",
    "\n",
    "    # 손실 함수와 옵티마이저 정의\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # 모델 훈련\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_inputs)\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # 테스트 데이터 준비\n",
    "    test_inputs = torch.tensor(scaled_data[-2]).unsqueeze(0).float()\n",
    "\n",
    "    # 모델 예측\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted = model(test_inputs)\n",
    "\n",
    "    # 스케일링 역변환\n",
    "    predicted = scaler.inverse_transform(predicted.squeeze().unsqueeze(0).numpy())\n",
    "\n",
    "    # 예측 결과 저장\n",
    "    kospis_index_prediction = predicted[0][-1]\n",
    "    predictions.append(kospis_index_prediction)\n",
    "\n",
    "# 예측 결과 평균 및 표준 편차 계산\n",
    "predictions = np.array(predictions)\n",
    "mean_prediction = np.mean(predictions)\n",
    "std_prediction = np.std(predictions)\n",
    "\n",
    "print(f'Mean of Predicted KOSPI Index: {mean_prediction:.2f}')\n",
    "print(f'Standard Deviation of Predicted KOSPI Index: {std_prediction:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52794,
     "status": "ok",
     "timestamp": 1686819662726,
     "user": {
      "displayName": "김민우",
      "userId": "15651798176472178488"
     },
     "user_tz": -540
    },
    "id": "lK7fRjQehQLO",
    "outputId": "4ef4763a-f0fb-4dca-90ee-01783afc6531"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0229\n",
      "Epoch [200/1000], Loss: 0.0120\n",
      "Epoch [300/1000], Loss: 0.0082\n",
      "Epoch [400/1000], Loss: 0.0063\n",
      "Epoch [500/1000], Loss: 0.0052\n",
      "Epoch [600/1000], Loss: 0.0047\n",
      "Epoch [700/1000], Loss: 0.0041\n",
      "Epoch [800/1000], Loss: 0.0038\n",
      "Epoch [900/1000], Loss: 0.0034\n",
      "Epoch [1000/1000], Loss: 0.0031\n",
      "Predicted KOSPI Index: 2259.52\n"
     ]
    }
   ],
   "source": [
    "#가중치가 반영된 코스피 주가지수 예측 트랜스포머\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('data100.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.iloc[:, 1:].values)  # 날짜 열 제외, 수치 데이터 스케일링\n",
    "\n",
    "# 훈련 데이터 준비\n",
    "train_data = scaled_data[:-1]  # 마지막 행 제외\n",
    "train_inputs = torch.tensor(train_data[:-1]).unsqueeze(0).float()  # 입력 데이터\n",
    "train_labels = torch.tensor(train_data[1:]).unsqueeze(0).float()  # 출력 데이터\n",
    "\n",
    "# 트랜스포머 모델 정의\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(hidden_size, num_heads, hidden_size),\n",
    "            num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, weights):\n",
    "        encoded = self.encoder(x)\n",
    "        weighted_encoded = encoded * weights.unsqueeze(0).unsqueeze(1).unsqueeze(1).expand(-1, encoded.size(1), -1, -1).transpose(0, 1)\n",
    "        decoded = self.decoder(weighted_encoded)\n",
    "        return decoded\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "input_size = train_inputs.shape[-1]\n",
    "hidden_size = 64\n",
    "output_size = train_labels.shape[-1]\n",
    "num_layers = 6\n",
    "num_heads = 4\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "\n",
    "# 모델 초기화\n",
    "model = TransformerModel(input_size, hidden_size, output_size, num_layers, num_heads)\n",
    "\n",
    "# 손실 함수와 옵티마이저 정의\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 가중치 설정\n",
    "weights = torch.randn(hidden_size)\n",
    "\n",
    "# 모델 훈련\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_inputs, weights)  # 가중치 전달\n",
    "    loss = criterion(outputs, train_labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 테스트 데이터 준비\n",
    "test_inputs = torch.tensor(scaled_data[-2]).unsqueeze(0).float()\n",
    "\n",
    "# 모델 예측\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    predicted = model(test_inputs, weights)  # 가중치 전달\n",
    "\n",
    "# 스케일링 역변환\n",
    "predicted = scaler.inverse_transform(predicted.squeeze(0).transpose(1, 3).reshape(-1, predicted.shape[-1])).reshape(-1, predicted.shape[-1])\n",
    "\n",
    "# 예측 결과 출력\n",
    "kospis_index_prediction = predicted[-1, -1]\n",
    "print(f'Predicted KOSPI Index: {kospis_index_prediction:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 497784,
     "status": "ok",
     "timestamp": 1686820163852,
     "user": {
      "displayName": "김민우",
      "userId": "15651798176472178488"
     },
     "user_tz": -540
    },
    "id": "T2Y0H5FuuTjT",
    "outputId": "5b055051-4916-426e-c83e-683f36b96cbd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0216\n",
      "Epoch [200/1000], Loss: 0.0200\n",
      "Epoch [300/1000], Loss: 0.0188\n",
      "Epoch [400/1000], Loss: 0.0178\n",
      "Epoch [500/1000], Loss: 0.0166\n",
      "Epoch [600/1000], Loss: 0.0150\n",
      "Epoch [700/1000], Loss: 0.0136\n",
      "Epoch [800/1000], Loss: 0.0120\n",
      "Epoch [900/1000], Loss: 0.0106\n",
      "Epoch [1000/1000], Loss: 0.0094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0217\n",
      "Epoch [200/1000], Loss: 0.0204\n",
      "Epoch [300/1000], Loss: 0.0193\n",
      "Epoch [400/1000], Loss: 0.0190\n",
      "Epoch [500/1000], Loss: 0.0179\n",
      "Epoch [600/1000], Loss: 0.0170\n",
      "Epoch [700/1000], Loss: 0.0156\n",
      "Epoch [800/1000], Loss: 0.0145\n",
      "Epoch [900/1000], Loss: 0.0130\n",
      "Epoch [1000/1000], Loss: 0.0120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0205\n",
      "Epoch [200/1000], Loss: 0.0194\n",
      "Epoch [300/1000], Loss: 0.0182\n",
      "Epoch [400/1000], Loss: 0.0177\n",
      "Epoch [500/1000], Loss: 0.0170\n",
      "Epoch [600/1000], Loss: 0.0159\n",
      "Epoch [700/1000], Loss: 0.0142\n",
      "Epoch [800/1000], Loss: 0.0128\n",
      "Epoch [900/1000], Loss: 0.0114\n",
      "Epoch [1000/1000], Loss: 0.0102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0205\n",
      "Epoch [200/1000], Loss: 0.0193\n",
      "Epoch [300/1000], Loss: 0.0183\n",
      "Epoch [400/1000], Loss: 0.0171\n",
      "Epoch [500/1000], Loss: 0.0159\n",
      "Epoch [600/1000], Loss: 0.0142\n",
      "Epoch [700/1000], Loss: 0.0123\n",
      "Epoch [800/1000], Loss: 0.0109\n",
      "Epoch [900/1000], Loss: 0.0095\n",
      "Epoch [1000/1000], Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0213\n",
      "Epoch [200/1000], Loss: 0.0197\n",
      "Epoch [300/1000], Loss: 0.0187\n",
      "Epoch [400/1000], Loss: 0.0176\n",
      "Epoch [500/1000], Loss: 0.0163\n",
      "Epoch [600/1000], Loss: 0.0146\n",
      "Epoch [700/1000], Loss: 0.0128\n",
      "Epoch [800/1000], Loss: 0.0115\n",
      "Epoch [900/1000], Loss: 0.0104\n",
      "Epoch [1000/1000], Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0213\n",
      "Epoch [200/1000], Loss: 0.0198\n",
      "Epoch [300/1000], Loss: 0.0189\n",
      "Epoch [400/1000], Loss: 0.0180\n",
      "Epoch [500/1000], Loss: 0.0165\n",
      "Epoch [600/1000], Loss: 0.0146\n",
      "Epoch [700/1000], Loss: 0.0127\n",
      "Epoch [800/1000], Loss: 0.0108\n",
      "Epoch [900/1000], Loss: 0.0096\n",
      "Epoch [1000/1000], Loss: 0.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0214\n",
      "Epoch [200/1000], Loss: 0.0197\n",
      "Epoch [300/1000], Loss: 0.0184\n",
      "Epoch [400/1000], Loss: 0.0169\n",
      "Epoch [500/1000], Loss: 0.0153\n",
      "Epoch [600/1000], Loss: 0.0136\n",
      "Epoch [700/1000], Loss: 0.0122\n",
      "Epoch [800/1000], Loss: 0.0112\n",
      "Epoch [900/1000], Loss: 0.0101\n",
      "Epoch [1000/1000], Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0209\n",
      "Epoch [200/1000], Loss: 0.0193\n",
      "Epoch [300/1000], Loss: 0.0186\n",
      "Epoch [400/1000], Loss: 0.0173\n",
      "Epoch [500/1000], Loss: 0.0158\n",
      "Epoch [600/1000], Loss: 0.0141\n",
      "Epoch [700/1000], Loss: 0.0127\n",
      "Epoch [800/1000], Loss: 0.0113\n",
      "Epoch [900/1000], Loss: 0.0101\n",
      "Epoch [1000/1000], Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0210\n",
      "Epoch [200/1000], Loss: 0.0193\n",
      "Epoch [300/1000], Loss: 0.0183\n",
      "Epoch [400/1000], Loss: 0.0177\n",
      "Epoch [500/1000], Loss: 0.0160\n",
      "Epoch [600/1000], Loss: 0.0148\n",
      "Epoch [700/1000], Loss: 0.0132\n",
      "Epoch [800/1000], Loss: 0.0117\n",
      "Epoch [900/1000], Loss: 0.0105\n",
      "Epoch [1000/1000], Loss: 0.0093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0215\n",
      "Epoch [200/1000], Loss: 0.0198\n",
      "Epoch [300/1000], Loss: 0.0192\n",
      "Epoch [400/1000], Loss: 0.0186\n",
      "Epoch [500/1000], Loss: 0.0175\n",
      "Epoch [600/1000], Loss: 0.0168\n",
      "Epoch [700/1000], Loss: 0.0155\n",
      "Epoch [800/1000], Loss: 0.0141\n",
      "Epoch [900/1000], Loss: 0.0127\n",
      "Epoch [1000/1000], Loss: 0.0114\n",
      "Mean of Predicted KOSPI Index: -3.36\n",
      "Standard Deviation of Predicted KOSPI Index: 3.06\n"
     ]
    }
   ],
   "source": [
    "#코스피 주가지수의 증감 퍼센트를 확인하는 트랜스포머\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('percent.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.iloc[:, 1:].values)  # 날짜 열 제외, 수치 데이터 스케일링\n",
    "\n",
    "# 훈련 데이터 준비\n",
    "train_data = scaled_data[:-1]  # 마지막 행 제외\n",
    "train_inputs = torch.tensor(train_data[:-1]).unsqueeze(0).float()  # 입력 데이터\n",
    "train_labels = torch.tensor(train_data[1:]).unsqueeze(0).float()  # 출력 데이터\n",
    "\n",
    "# 트랜스포머 모델 정의\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(hidden_size, num_heads, hidden_size),\n",
    "            num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, weights):\n",
    "        encoded = self.encoder(x)\n",
    "        weighted_encoded = encoded * weights.unsqueeze(0).unsqueeze(1).unsqueeze(1).expand(-1, encoded.size(1), -1, -1).transpose(0, 1)\n",
    "        decoded = self.decoder(weighted_encoded)\n",
    "        return decoded\n",
    "\n",
    "input_size = train_inputs.shape[-1]\n",
    "hidden_size = 64\n",
    "output_size = train_labels.shape[-1]\n",
    "num_layers = 6\n",
    "num_heads = 4\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "num_runs = 10\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "\n",
    "    model = TransformerModel(input_size, hidden_size, output_size, num_layers, num_heads)\n",
    "\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    weights = torch.randn(hidden_size)\n",
    "\n",
    "    # 모델 훈련\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_inputs, weights)  # 가중치 전달\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # 테스트 데이터 준비\n",
    "    test_inputs = torch.tensor(scaled_data[-2]).unsqueeze(0).float()\n",
    "\n",
    "    # 모델 예측\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted = model(test_inputs, weights)  # 가중치 전달\n",
    "\n",
    "    # 스케일링 역변환\n",
    "    predicted = scaler.inverse_transform(predicted.squeeze(0).transpose(1, 3).reshape(-1, predicted.shape[-1])).reshape(-1, predicted.shape[-1])\n",
    "\n",
    "    # 예측 결과 저장\n",
    "    predictions.append(predicted[-1, -1])\n",
    "\n",
    "# 예측 결과의 평균과 표준 편차 계산\n",
    "predictions = np.array(predictions)\n",
    "mean_prediction = predictions.mean()\n",
    "std_prediction = predictions.std()\n",
    "\n",
    "print(f'Mean of Predicted KOSPI Index: {mean_prediction:.2f}')\n",
    "print(f'Standard Deviation of Predicted KOSPI Index: {std_prediction:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 822829,
     "status": "ok",
     "timestamp": 1686730902925,
     "user": {
      "displayName": "김민우",
      "userId": "15651798176472178488"
     },
     "user_tz": -540
    },
    "id": "ZvtnlcNUuT5L",
    "outputId": "a22df553-947a-4b13-e67b-d5f2ba45fffc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0224\n",
      "Epoch [200/1000], Loss: 0.0200\n",
      "Epoch [300/1000], Loss: 0.0192\n",
      "Epoch [400/1000], Loss: 0.0181\n",
      "Epoch [500/1000], Loss: 0.0168\n",
      "Epoch [600/1000], Loss: 0.0155\n",
      "Epoch [700/1000], Loss: 0.0140\n",
      "Epoch [800/1000], Loss: 0.0126\n",
      "Epoch [900/1000], Loss: 0.0112\n",
      "Epoch [1000/1000], Loss: 0.0101\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0216\n",
      "Epoch [200/1000], Loss: 0.0198\n",
      "Epoch [300/1000], Loss: 0.0186\n",
      "Epoch [400/1000], Loss: 0.0178\n",
      "Epoch [500/1000], Loss: 0.0171\n",
      "Epoch [600/1000], Loss: 0.0162\n",
      "Epoch [700/1000], Loss: 0.0152\n",
      "Epoch [800/1000], Loss: 0.0142\n",
      "Epoch [900/1000], Loss: 0.0126\n",
      "Epoch [1000/1000], Loss: 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0221\n",
      "Epoch [200/1000], Loss: 0.0203\n",
      "Epoch [300/1000], Loss: 0.0195\n",
      "Epoch [400/1000], Loss: 0.0190\n",
      "Epoch [500/1000], Loss: 0.0181\n",
      "Epoch [600/1000], Loss: 0.0170\n",
      "Epoch [700/1000], Loss: 0.0159\n",
      "Epoch [800/1000], Loss: 0.0148\n",
      "Epoch [900/1000], Loss: 0.0136\n",
      "Epoch [1000/1000], Loss: 0.0122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0217\n",
      "Epoch [200/1000], Loss: 0.0199\n",
      "Epoch [300/1000], Loss: 0.0191\n",
      "Epoch [400/1000], Loss: 0.0179\n",
      "Epoch [500/1000], Loss: 0.0162\n",
      "Epoch [600/1000], Loss: 0.0147\n",
      "Epoch [700/1000], Loss: 0.0128\n",
      "Epoch [800/1000], Loss: 0.0112\n",
      "Epoch [900/1000], Loss: 0.0097\n",
      "Epoch [1000/1000], Loss: 0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0208\n",
      "Epoch [200/1000], Loss: 0.0195\n",
      "Epoch [300/1000], Loss: 0.0189\n",
      "Epoch [400/1000], Loss: 0.0182\n",
      "Epoch [500/1000], Loss: 0.0173\n",
      "Epoch [600/1000], Loss: 0.0158\n",
      "Epoch [700/1000], Loss: 0.0140\n",
      "Epoch [800/1000], Loss: 0.0119\n",
      "Epoch [900/1000], Loss: 0.0102\n",
      "Epoch [1000/1000], Loss: 0.0091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0220\n",
      "Epoch [200/1000], Loss: 0.0199\n",
      "Epoch [300/1000], Loss: 0.0190\n",
      "Epoch [400/1000], Loss: 0.0181\n",
      "Epoch [500/1000], Loss: 0.0175\n",
      "Epoch [600/1000], Loss: 0.0169\n",
      "Epoch [700/1000], Loss: 0.0160\n",
      "Epoch [800/1000], Loss: 0.0146\n",
      "Epoch [900/1000], Loss: 0.0131\n",
      "Epoch [1000/1000], Loss: 0.0116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0207\n",
      "Epoch [200/1000], Loss: 0.0194\n",
      "Epoch [300/1000], Loss: 0.0186\n",
      "Epoch [400/1000], Loss: 0.0179\n",
      "Epoch [500/1000], Loss: 0.0164\n",
      "Epoch [600/1000], Loss: 0.0149\n",
      "Epoch [700/1000], Loss: 0.0134\n",
      "Epoch [800/1000], Loss: 0.0118\n",
      "Epoch [900/1000], Loss: 0.0106\n",
      "Epoch [1000/1000], Loss: 0.0095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0211\n",
      "Epoch [200/1000], Loss: 0.0195\n",
      "Epoch [300/1000], Loss: 0.0188\n",
      "Epoch [400/1000], Loss: 0.0174\n",
      "Epoch [500/1000], Loss: 0.0159\n",
      "Epoch [600/1000], Loss: 0.0142\n",
      "Epoch [700/1000], Loss: 0.0123\n",
      "Epoch [800/1000], Loss: 0.0107\n",
      "Epoch [900/1000], Loss: 0.0093\n",
      "Epoch [1000/1000], Loss: 0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0204\n",
      "Epoch [200/1000], Loss: 0.0190\n",
      "Epoch [300/1000], Loss: 0.0178\n",
      "Epoch [400/1000], Loss: 0.0162\n",
      "Epoch [500/1000], Loss: 0.0142\n",
      "Epoch [600/1000], Loss: 0.0123\n",
      "Epoch [700/1000], Loss: 0.0109\n",
      "Epoch [800/1000], Loss: 0.0095\n",
      "Epoch [900/1000], Loss: 0.0084\n",
      "Epoch [1000/1000], Loss: 0.0076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0219\n",
      "Epoch [200/1000], Loss: 0.0202\n",
      "Epoch [300/1000], Loss: 0.0188\n",
      "Epoch [400/1000], Loss: 0.0173\n",
      "Epoch [500/1000], Loss: 0.0163\n",
      "Epoch [600/1000], Loss: 0.0146\n",
      "Epoch [700/1000], Loss: 0.0132\n",
      "Epoch [800/1000], Loss: 0.0120\n",
      "Epoch [900/1000], Loss: 0.0110\n",
      "Epoch [1000/1000], Loss: 0.0099\n",
      "Mean of Predicted KOSPI Index: -2.57\n",
      "Standard Deviation of Predicted KOSPI Index: 3.29\n"
     ]
    }
   ],
   "source": [
    "#코스피 주가지수의 증감 퍼센트 및 가중치와 10회 실행 후 평균과 표준편차를 구하는 트랜스포머\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('percent.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.iloc[:, 1:].values)  # 날짜 열 제외, 수치 데이터 스케일링\n",
    "\n",
    "# 훈련 데이터 준비\n",
    "train_data = scaled_data[:-1]  # 마지막 행 제외\n",
    "train_inputs = torch.tensor(train_data[:-1]).unsqueeze(0).float()  # 입력 데이터\n",
    "train_labels = torch.tensor(train_data[1:]).unsqueeze(0).float()  # 출력 데이터\n",
    "\n",
    "# 트랜스포머 모델 정의\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(hidden_size, num_heads, hidden_size),\n",
    "            num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, weights):\n",
    "        encoded = self.encoder(x)\n",
    "        weighted_encoded = encoded * weights.unsqueeze(0).unsqueeze(1).unsqueeze(1).expand(-1, encoded.size(1), -1, -1).transpose(0, 1)\n",
    "        decoded = self.decoder(weighted_encoded)\n",
    "        return decoded\n",
    "\n",
    "input_size = train_inputs.shape[-1]\n",
    "hidden_size = 64\n",
    "output_size = train_labels.shape[-1]\n",
    "num_layers = 6\n",
    "num_heads = 4\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "num_runs = 10\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "\n",
    "    model = TransformerModel(input_size, hidden_size, output_size, num_layers, num_heads)\n",
    "\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "\n",
    "    weights = torch.randn(hidden_size)\n",
    "\n",
    "    # 모델 훈련\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_inputs, weights)  # 가중치 전달\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # 테스트 데이터 준비\n",
    "    test_inputs = torch.tensor(scaled_data[-2]).unsqueeze(0).float()\n",
    "\n",
    "    # 모델 예측\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted = model(test_inputs, weights)  # 가중치 전달\n",
    "\n",
    "    # 스케일링 역변환\n",
    "    predicted = scaler.inverse_transform(predicted.squeeze(0).transpose(1, 3).reshape(-1, predicted.shape[-1])).reshape(-1, predicted.shape[-1])\n",
    "\n",
    "    # 예측 결과 저장\n",
    "    predictions.append(predicted[-1, -1])\n",
    "\n",
    "# 예측 결과의 평균과 표준 편차 계산\n",
    "predictions = np.array(predictions)\n",
    "mean_prediction = predictions.mean()\n",
    "std_prediction = predictions.std()\n",
    "\n",
    "print(f'Mean of Predicted KOSPI Index: {mean_prediction:.2f}')\n",
    "print(f'Standard Deviation of Predicted KOSPI Index: {std_prediction:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104724,
     "status": "ok",
     "timestamp": 1686820284874,
     "user": {
      "displayName": "김민우",
      "userId": "15651798176472178488"
     },
     "user_tz": -540
    },
    "id": "1_EoTNrXIfYP",
    "outputId": "2a4feb36-fe7b-4859-f313-5b7ee1b639f8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:928: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0106\n",
      "Epoch [200/1000], Loss: 0.0097\n",
      "Epoch [300/1000], Loss: 0.0093\n",
      "Epoch [400/1000], Loss: 0.0088\n",
      "Epoch [500/1000], Loss: 0.0084\n",
      "Epoch [600/1000], Loss: 0.0077\n",
      "Epoch [700/1000], Loss: 0.0069\n",
      "Epoch [800/1000], Loss: 0.0060\n",
      "Epoch [900/1000], Loss: 0.0053\n",
      "Epoch [1000/1000], Loss: 0.0047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py:928: UserWarning: Using a target size (torch.Size([1, 217, 64])) that is different to the input size (torch.Size([217, 1, 217, 64])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.smooth_l1_loss(input, target, reduction=self.reduction, beta=self.beta)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.0105\n",
      "Epoch [200/1000], Loss: 0.0096\n",
      "Epoch [300/1000], Loss: 0.0090\n",
      "Epoch [400/1000], Loss: 0.0082\n",
      "Epoch [500/1000], Loss: 0.0074\n",
      "Epoch [600/1000], Loss: 0.0065\n",
      "Epoch [700/1000], Loss: 0.0058\n",
      "Epoch [800/1000], Loss: 0.0051\n",
      "Epoch [900/1000], Loss: 0.0045\n",
      "Epoch [1000/1000], Loss: 0.0043\n",
      "Mean of Predicted KOSPI Index: -0.54\n",
      "Standard Deviation of Predicted KOSPI Index: 0.10\n"
     ]
    }
   ],
   "source": [
    "#위 코드에서 loss함수를 Huber Loss로 대체한 코드\n",
    "\n",
    "# CSV 파일 불러오기\n",
    "data = pd.read_csv('percent.csv')\n",
    "\n",
    "# 데이터 전처리\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(data.iloc[:, 1:].values)  # 날짜 열 제외, 수치 데이터 스케일링\n",
    "\n",
    "# 훈련 데이터 준비\n",
    "train_data = scaled_data[:-1]  # 마지막 행 제외\n",
    "train_inputs = torch.tensor(train_data[:-1]).unsqueeze(0).float()  # 입력 데이터\n",
    "train_labels = torch.tensor(train_data[1:]).unsqueeze(0).float()  # 출력 데이터\n",
    "\n",
    "# 트랜스포머 모델 정의\n",
    "class TransformerModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers, num_heads):\n",
    "        super(TransformerModel, self).__init__()\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(hidden_size, num_heads, hidden_size),\n",
    "            num_layers\n",
    "        )\n",
    "        self.decoder = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x, weights):\n",
    "        encoded = self.encoder(x)\n",
    "        weighted_encoded = encoded * weights.unsqueeze(0).unsqueeze(1).unsqueeze(1).expand(-1, encoded.size(1), -1, -1).transpose(0, 1)\n",
    "        decoded = self.decoder(weighted_encoded)\n",
    "        return decoded\n",
    "\n",
    "input_size = train_inputs.shape[-1]\n",
    "hidden_size = 64\n",
    "output_size = train_labels.shape[-1]\n",
    "num_layers = 6\n",
    "num_heads = 4\n",
    "num_epochs = 1000\n",
    "learning_rate = 0.001\n",
    "num_runs = 2\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for _ in range(num_runs):\n",
    "\n",
    "    model = TransformerModel(input_size, hidden_size, output_size, num_layers, num_heads)\n",
    "\n",
    "    criterion = nn.SmoothL1Loss()  # Huber Loss로 대체\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    weights = torch.randn(hidden_size)\n",
    "\n",
    "    # 모델 훈련\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(train_inputs, weights)  # 가중치 전달\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (epoch+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    # 테스트 데이터 준비\n",
    "    test_inputs = torch.tensor(scaled_data[-2]).unsqueeze(0).float()\n",
    "\n",
    "    # 모델 예측\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predicted = model(test_inputs, weights)  # 가중치 전달\n",
    "\n",
    "    # 스케일링 역변환\n",
    "    predicted = scaler.inverse_transform(predicted.squeeze(0).transpose(1, 3).reshape(-1, predicted.shape[-1])).reshape(-1, predicted.shape[-1])\n",
    "\n",
    "    # 예측 결과 저장\n",
    "    predictions.append(predicted[-1, -1])\n",
    "\n",
    "# 예측 결과의 평균과 표준 편차 계산\n",
    "predictions = np.array(predictions)\n",
    "mean_prediction = predictions.mean()\n",
    "std_prediction = predictions.std()\n",
    "\n",
    "print(f'Mean of Predicted KOSPI Index: {mean_prediction:.2f}')\n",
    "print(f'Standard Deviation of Predicted KOSPI Index: {std_prediction:.2f}')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNbtQNupVx6bCyTgQePo64y",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
